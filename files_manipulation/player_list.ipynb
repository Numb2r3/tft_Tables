{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sql_functions as sql_int\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Names from Tournament\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take the playerlist and reduce duplikates in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_import = pd.read_csv('/program/tft_overview/tft_Tables/data_sheets/name_list_GSC1.csv',\n",
    "                         dtype={'liquipedia_name' : str,'coutry_flag' : str} )\n",
    "df_player_import = player_import.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_player_import = df_player_import.rename(columns={'liquipedia_name' : 'import_name'})\n",
    "df_player_import['import_name_lower'] = df_player_import['import_name'].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "df_player_import = df_player_import.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same liquipedia name but different country correct the entrys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>import_name</th>\n",
       "      <th>import_name_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [import_name, import_name_lower]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_player_import[df_player_import.duplicated(keep = False, subset=['import_name']) == True].sort_values(by='import_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### delete double entrys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_player_import.drop([0],inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Names with *alternative_names*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'tft_tables'\n",
    "sql_query = f'''select player_name, liquipedia_name, names_id, a.player_id \n",
    "                FROM alternative_names a \n",
    "                LEFT JOIN players p ON p.player_id = a.player_id ;\n",
    "                '''\n",
    "\n",
    "alternative_names = pd.DataFrame(sql_int.get_data_mysql(sql_query),\n",
    "                                    columns=['player_name','liquipedia_name','names_id','player_id'])\n",
    "df_alternative_names = alternative_names.copy()\n",
    "\n",
    "df_alternative_names[['player_name','liquipedia_name']] = df_alternative_names[['player_name','liquipedia_name']].apply(lambda x: x.str.lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace the imported names with liquipedia_names from the alternative list.   \n",
    "If there was someone with his alternative name in, they have now liquipedia_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>import_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lelouch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wet jungler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lastkardax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l3s coco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tsarou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>hyunter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>swellertiger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>banefirexd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>omino blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>skramskli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      import_name\n",
       "0         lelouch\n",
       "1     wet jungler\n",
       "2      lastkardax\n",
       "3        l3s coco\n",
       "4          tsarou\n",
       "..            ...\n",
       "123       hyunter\n",
       "124  swellertiger\n",
       "125    banefirexd\n",
       "126    omino blue\n",
       "127     skramskli\n",
       "\n",
       "[128 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_import_alternative = (pd.merge(df_player_import['import_name_lower'], df_alternative_names[['player_name','liquipedia_name']], how=\"left\", left_on='import_name_lower',right_on='player_name')\n",
    "                               .rename(columns={'import_name_lower' : 'import_name'}))\n",
    "\n",
    "df_merge_import_alternative.loc[df_merge_import_alternative['player_name'].notna(), 'import_name'] = df_merge_import_alternative['liquipedia_name']\n",
    "df_merge_import_alternative = df_merge_import_alternative.drop(columns=['player_name','liquipedia_name']).drop_duplicates()\n",
    "df_merge_import_alternative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd check cause 2nd merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>import_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [import_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_import_alternative[df_merge_import_alternative.duplicated(keep= False, subset=['import_name']) == True].sort_values(by='import_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Names in *players*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = f'''select liquipedia_name, player_id from {schema}.players;'''\n",
    "\n",
    "\n",
    "liquipedia_names = pd.DataFrame(sql_int.get_data_mysql(sql_query),\n",
    "                                columns=['liquipedia_name','player_id'])\n",
    "\n",
    "df_liquipedia_names = liquipedia_names.copy()\n",
    "df_liquipedia_names['liquipedia_name'] = df_liquipedia_names['liquipedia_name'].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "df_merge_import_alternatives_liquipedia =pd.merge(\n",
    "                                            df_merge_import_alternative,df_liquipedia_names['liquipedia_name'], how='left',\n",
    "                                            left_on= 'import_name', right_on='liquipedia_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_new_players are all players we put in over our names_list, which arn't in *players* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_players = df_merge_import_alternatives_liquipedia[df_merge_import_alternatives_liquipedia['liquipedia_name'] \n",
    "                                                         .isna()].drop(columns=['liquipedia_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push new Names to *alternative_names*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_new_players = df_new_players['import_name'].to_list()\n",
    "list_liquipedia_name = df_liquipedia_names['liquipedia_name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_new_players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Check similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_names = []\n",
    "for i in list_new_players :\n",
    "    for j in list_liquipedia_name:\n",
    "        if i == j:\n",
    "            pass\n",
    "        elif  Levenshtein.jaro(i,j) > 0.75:\n",
    "            similar_names.append([j,i])\n",
    "df_similar_names = pd.DataFrame(similar_names,columns=['liquipedia_name','import_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Controll\n",
    "***This list must be controlled before pushed!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liquipedia_name</th>\n",
       "      <th>import_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [liquipedia_name, import_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_similar_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some magic here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32md:\\program\\miniconda\\envs\\data_base_Sep23\\Lib\\site-packages\\pandas\\core\\indexing.py:1618\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1617\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1618\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_take_with_is_copy(key, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m   1619\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   1620\u001b[0m     \u001b[39m# re-raise with different error message\u001b[39;00m\n",
      "File \u001b[1;32md:\\program\\miniconda\\envs\\data_base_Sep23\\Lib\\site-packages\\pandas\\core\\generic.py:3948\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3941\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3942\u001b[0m \u001b[39mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   3943\u001b[0m \u001b[39mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3946\u001b[0m \u001b[39mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   3947\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3948\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_take(indices\u001b[39m=\u001b[39mindices, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m   3949\u001b[0m \u001b[39m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "File \u001b[1;32md:\\program\\miniconda\\envs\\data_base_Sep23\\Lib\\site-packages\\pandas\\core\\generic.py:3932\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[1;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[0;32m   3930\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 3932\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mtake(\n\u001b[0;32m   3933\u001b[0m     indices,\n\u001b[0;32m   3934\u001b[0m     axis\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_block_manager_axis(axis),\n\u001b[0;32m   3935\u001b[0m     verify\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   3936\u001b[0m     convert_indices\u001b[39m=\u001b[39mconvert_indices,\n\u001b[0;32m   3937\u001b[0m )\n\u001b[0;32m   3938\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\program\\miniconda\\envs\\data_base_Sep23\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:960\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[39mif\u001b[39;00m convert_indices:\n\u001b[1;32m--> 960\u001b[0m     indexer \u001b[39m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[39m=\u001b[39mverify)\n\u001b[0;32m    962\u001b[0m new_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mtake(indexer)\n",
      "File \u001b[1;32md:\\program\\miniconda\\envs\\data_base_Sep23\\Lib\\site-packages\\pandas\\core\\indexers\\utils.py:284\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[1;34m(indices, n, verify)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m--> 284\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mindices are out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    285\u001b[0m \u001b[39mreturn\u001b[39;00m indices\n",
      "\u001b[1;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\program\\tft_overview\\tft_Tables\\files_manipulation\\player_list.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/program/tft_overview/tft_Tables/files_manipulation/player_list.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_similar_names \u001b[39m=\u001b[39m df_similar_names\u001b[39m.\u001b[39miloc[[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/program/tft_overview/tft_Tables/files_manipulation/player_list.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_similar_names\n",
      "File \u001b[1;32md:\\program\\miniconda\\envs\\data_base_Sep23\\Lib\\site-packages\\pandas\\core\\indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1100\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m   1102\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m-> 1103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32md:\\program\\miniconda\\envs\\data_base_Sep23\\Lib\\site-packages\\pandas\\core\\indexing.py:1647\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1645\u001b[0m \u001b[39m# a list of integers\u001b[39;00m\n\u001b[0;32m   1646\u001b[0m \u001b[39melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[1;32m-> 1647\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_list_axis(key, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m   1649\u001b[0m \u001b[39m# a single integer\u001b[39;00m\n\u001b[0;32m   1650\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1651\u001b[0m     key \u001b[39m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[1;32md:\\program\\miniconda\\envs\\data_base_Sep23\\Lib\\site-packages\\pandas\\core\\indexing.py:1621\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1618\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_take_with_is_copy(key, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m   1619\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   1620\u001b[0m     \u001b[39m# re-raise with different error message\u001b[39;00m\n\u001b[1;32m-> 1621\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mpositional indexers are out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "df_similar_names = df_similar_names.iloc[[0,1]]\n",
    "\n",
    "df_similar_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data push\n",
    "**Hier ist der Push in die Database, be sure**\n",
    "\n",
    "The datafram has to be established"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ACHTUNG é ist das selbe wie e\n",
    "df_similar_names_push = pd.merge(\n",
    "                                df_similar_names,df_liquipedia_names[['liquipedia_name','player_id']], how='left',\n",
    "                                left_on= 'liquipedia_name', right_on='liquipedia_name').drop(columns=['liquipedia_name'])\n",
    "\n",
    "\n",
    "df_player_import = player_import.copy()\n",
    "df_player_import['name_lower'] = df_player_import['import_name'].apply(lambda x : x.lower())\n",
    "df_player_import = df_player_import.drop_duplicates(subset=['name_lower'])\n",
    "df_similar_names_push = (pd.merge(df_similar_names_push,df_player_import,how='left', left_on='import_name',right_on='name_lower')\n",
    "                         .drop(columns=['import_name_x','name_lower'])\n",
    "                         .rename(columns={'import_name_y': 'player_name'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alternative_names table was imported successfully.\n"
     ]
    }
   ],
   "source": [
    "sql_int.push_to_database(df_similar_names_push,'alternative_names',sql_int.get_engine_alchemy(),'tft_tables')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push new names in *players*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_players = pd.merge(df_new_players,df_similar_names, how='left',\n",
    "                              left_on= 'import_name', right_on='import_name')  ## on player name cause all with same liquipedia_name are already out\n",
    "df_new_players = df_new_players[df_new_players['liquipedia_name'].isna()]\n",
    "df_new_players = df_new_players.drop(columns=['liquipedia_name'])\n",
    "new_players_push = (pd.merge(df_new_players['import_name'], df_player_import, how=\"left\", left_on='import_name',right_on='name_lower')\n",
    "                    .drop(columns=['import_name_x','name_lower'])\n",
    "                    .rename(columns={'import_name_y' : 'liquipedia_name','country_flag' : 'country_name'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The players table was imported successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sql_int.push_to_database(new_players_push,'players',sql_int.get_engine_alchemy(),'tft_tables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push these new names in alternative_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = f'''select liquipedia_name, player_id from {schema}.players;'''\n",
    "df_liquipedia_names = pd.DataFrame(sql_int.get_data_mysql(sql_query),\n",
    "                                columns=['liquipedia_name','player_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alternative_names_push = (pd.merge(new_players_push['liquipedia_name'],df_liquipedia_names,how='left', left_on='liquipedia_name',right_on='liquipedia_name')\n",
    "                             .rename(columns={'liquipedia_name':'player_name'})\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alternative_names table was imported successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sql_int.push_to_database(df_alternative_names_push,'alternative_names',sql_int.get_engine_alchemy(),'tft_tables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df #updating data in dataframe wäre der dataframe mit den liquid_namen mit flagge. (die vorher keine gehabt haben)\n",
    "\n",
    "s_update = \"\" #String of updations\n",
    "\n",
    "# Loop through the data frame\n",
    "\n",
    "for i in range(len(df)):\n",
    "    s_update += \"update players set country_name = '%s' where liquipedia_name = '%s';\" %(df[country_name][i], df[liquipedia_name][i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_base_Sep23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
